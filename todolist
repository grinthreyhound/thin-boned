//2 valid approaches: conditional poisson regression or inserting the matching set into poisson as ranom effect variable.
//though likely that accounting for matching will make little difference so can do sensitivity analysis to that effect
//Using own date confirmed as the right thing to do.  
//NB data definitely overdispersed, so negative binomial (xtpoisson) appropriate. 

//get the data
//start with a small section
*set memory 1g
cd "H:\JOE\THIN"
//use in 1/1000 using consults3m.dta
//use consults3m.dta
//use in 1/1000 using consultation15_ss2_CC.dta
//use consultation15_ss2_CC.dta
//create a smaller file:
*use "H:\JOE\THIN\consultation15_ss2withcats.dta"
//drop some blank/unneeded columns:
*drop  medcode_p1 prescomplaint1 medcode_p2 prescomplaint2 medcode_s1 symptom1 medcode_s2 symptom2 medcode_s3 symptom3 medcode_s4 symptom4 medcode_s5 symptom5 medcode_s6 symptom6 medcode_s7 symptom7 medcode_s8 symptom8 medcode_e1 medcode_e1 examination1 medcode_e2 examination2 medcode_e3 examination3 medcode_e4 examination4 medcode_d1 diagnosis1 medcode_d2 diagnosis2 medcode_d3 diagnosis3 medcode_d4 diagnosis4 medcode_d5 diagnosis5 medcode_d6 diagnosis6 medcode_d7 diagnosis7 medcode_d8 diagnosis8 medcode_i1 intervention1 medcode_i2 intervention2 medcode_i3 intervention3 medcode_i4 intervention4 medcode_i5 intervention5 medcode_i6 intervention6 medcode_i7 intervention7 medcode_i8 intervention8 medcode_i9 intervention9 medcode_i10 intervention10 medcode_i11 intervention11 medcode_m1 management1 medcode_m2 management2 medcode_m3 management3 medcode_m4 management4 medcode_m5 management5 medcode_m6 management6 medcode_m7 management7 medcode_m8 management8 medcode_m9 management9
*save "H:\JOE\THIN\consult15CatsSimple.dta"

use "H:\JOE\THIN\consult15CatIndex.dta"
// for the 15 month data case is 1, control is 2, recode this:
recode case_control (2=0)

// create new index date: where it is the last contact in the record for controls only
//(because of the looseness of matching in time) 
//problem - no data exists for after the index dates


//drop any entries more than 3 months before the new indexdate
//by id, sort: egen lasttime = max(eventdate)
//format lasttime %td
//replace lasttime = indexdate if case_control==0
gen timebeforeindex = indexdate-eventdate
drop if timebeforeindex >91

//create a new entry date
gen enter = indexdate-91

//For the whole dataset only: check duration of time in study with events occuring: 15 month data 456 days,3 month data 90 days
*by id, sort: egen firstdate = min(eventdate)
*gen duration = lasttime - firstdate
*sum duration

//and new scaling for events: time before lasttime
*gen studyeventdate= eventdate - lasttime
*replace studyeventdate = sqrt(studyeventdate^2)

//need a variable for any failure:
*generate failure=1

//need to compare baseline contacts between cases and controls: 
//stset the data to indicate it is survival time data with multiple lines per person (specify id)
//Need to specify exit or else it terminates after first failure
//Some duplicates where 

preserve
stset eventdate, id(id) fail(consult_group3) exit(time .) origin(enter) scale(1)
stsplit earlylate, at(7(7)91) after(enter) 
stset, clear
//need a matching variable: strings not allowed, so number them: (can't do this before stsetting as doesn't expand clusterid)
sort id
by id: generate mgroup = id if case_control ==1
replace mgroup = case_id if case_control ==0
egen clusterid = group(mgroup)

//to use Xt poisson need to xtset the data: delare it to be panel data: xtset panelvar timevar
//xtsetting is a new command, //Panel data assumes there have been observations I think, so STset/stsplit first
//cant use string id so need to group this  NB: if want to keep labels could instead use : encode id,gen(numid) 
egen numid =group(id)

//now need to sort out multiples: casued by some presenting >1 time in stplit period (including >1 per day for some)
//generate dup to count duplicates
sort numid earlylate
quietly by numid earlylate: gen dup = cond(_N==1,0,_n)
//get the number of events in each duplicated time period
by numid earlylate: egen events = max(dup)
//drop the duplicates but keep the number of events
drop if dup<events
//Make failure missing values ==0
recode failure(.=0)
//now redefine the failures to be the number of events: failure is now the number of events in the time period
replace failure = events if events>failure

//drop the last events - the ones selected upon, but only if there are no multiples in that time period:
replace failure=failure-1 if lasttime==eventdate & failure!=0
//now we have panel data with time from event in earlylate and number of events in each time period in failure
//Need to turn earlylate into an ordinal thingy of weeks before index
recode earlylate (0=13) (7=12) (14=11) (21=10) (28=9) (35=8) (42=7) (49=6) (56=5) (63=4) (70=3) (77=2) (84=1) 
*duplicates report earlylate numid
xtset clusterid
*xtpoisson failure case_control, irr 

foreach i of num 1/13 {
preserve
keep if earlylate==`i'
xtpoisson failure case_control, irr
restore
}

//what's going on in week-2?
preserve
tab failure case_cont if earlylate==2
keep if earlylate==2
tab case_cont failure, row //looks like in week before kids much more likely to have >1 event if controls.
//This may be the nature of the high attending controls - the sensitivity analysis using cases as own controls. 
//also might be in nature of their attendances - breakdown will be interesting
//might be that small number of higher attendances are overrepresented as larger number of controls
xtpoisson failure i.case_control, irr
restore

